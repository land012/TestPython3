<?xml version="1.0" encoding="UTF-8"?><configuration>
<property><name>dfs.client.transfer.limit.usetk</name><value>false</value></property>
<property><name>mapred.overall.shuffle.service.enable.min.live.shuffle.services</name><value>1000</value></property>
<property><name>job.end.retry.interval</name><value>30000</value></property>
<property><name>abaci.squeezer.trial.run.queue.min.cpu</name><value>100</value></property>
<property><name>io.bytes.per.checksum</name><value>512</value></property>
<property><name>dce.enable.map.pipeline</name><value>false</value></property>
<property><name>mapred.hce.replace.streaming</name><value>true</value></property>
<property><name>dce.shuffler.start.options</name><value>--dce_zk_address=@dce_zk_address@ --dce_zk_node_path=@dce_zk_node_path@ --dce_rig_cluster_name=@dce_rig_cluster_name@ --dce_worker_port=@dce_worker_port@ --dce_worker_max_used_memory_bytes=@dce_worker_max_used_memory_bytes@ --dce_worker_heartbeat_interval_sec=@dce_worker_heartbeat_interval_sec@</value></property>
<property><name>dfs.client.auth.method</name><value>0</value></property>
<property><name>mapred.queue.default.acl-administer-jobs</name><value>root root</value></property>
<property><name>mapred.task.profile.reduces</name><value>0-2</value></property>
<property><name>mapred.job.reuse.jvm.num.tasks</name><value>1</value></property>
<property><name>mapred.job.auditsFile.checkingInterval.minute</name><value>1440</value></property>
<property><name>mapred.job.history.http.address</name><value>yq01-tianqi-historyserver.dmop.baidu.com:8031</value></property>
<property><name>dfs.batch.open.block.max</name><value>8192</value></property>
<property><name>mapred.reduce.tasks.speculative.execution</name><value>true</value></property>
<property><name>abaci.squeezer.trial.run.capacity.supplement</name><value>true</value></property>
<property><name>abaci.squeezer.trial.run</name><value>true</value></property>
<property><name>abaci.shuffle.service.max.segment.swap.file.length</name><value>134217728</value></property>
<property><name>mapred.job.name</name><value>xingyongyue.igc_click_spreads_2017102701</value></property>
<property><name>abaci.use.instance.notification</name><value>true</value></property>
<property><name>dfs.permissions.supergroup</name><value>root</value></property>
<property><name>mapred.job.shuffle.input.buffer.size</name><value>256</value></property>
<property><name>io.seqfile.sorter.recordlimit</name><value>1000000</value></property>
<property><name>abaci.metamaster.name</name><value>yq01-tianqi</value></property>
<property><name>dce.shuffle.session.output.dir.max.replication</name><value>3</value></property>
<property><name>abaci.support.middle.data.path</name><value>/app/dc/deva/system/dfsData</value></property>
<property><name>mapred.job.shuffle.service.enable.max.reduces</name><value>15000</value></property>
<property><name>abaci.shuffle.service.memory.usage.threshold.for.swap</name><value>134217728</value></property>
<property><name>mapred.job.max.existTime.millisecond</name><value>5184000000</value></property>
<property><name>mapred.task.tracker.http.address</name><value>0.0.0.0:8060</value></property>
<property><name>mapred.cache.archives.timestamps</name><value>1497344142000,1506306379000,1509041404000</value></property>
<property><name>resource.manager.impl.local</name><value>com.baidu.inf.abaci.resource.LocalResourceManager</value></property>
<property><name>abaci.metamaster.http.address</name><value>yq01-tianqi-job.dmop.baidu.com:8030</value></property>
<property><name>resource.manager.impl.ark</name><value>com.baidu.inf.abaci.resource.ArkResourceManager</value></property>
<property><name>abaci.appmaster.resource.update.interval</name><value>10000</value></property>
<property><name>fs.ramfs.impl</name><value>org.apache.hadoop.fs.InMemoryFileSystem</value></property>
<property><name>mapred.system.dir</name><value>/system/mapred</value></property>
<property><name>abaci.metamaster.appstatus.expire.interval</name><value>600000</value></property>
<property><name>abaci.appmaster.wait.appslave.time</name><value>600000</value></property>
<property><name>mapred.task.tracker.report.address</name><value>127.0.0.1:0</value></property>
<property><name>job.history.index.dbname</name><value>/home/mapred/jobIndexDB</value></property>
<property><name>abaci.job.tag.message.history.abnormal.processSpeed</name><value>异常: 处理速度=@processSpeed@, 输入数据量=@inputSize@, 并发满足=@ccs@</value></property>
<property><name>dce.shuffler.memory.mb</name><value>3500</value></property>
<property><name>abaci.metamaster.rpc.handler</name><value>100</value></property>
<property><name>abaci.squeezer.resource.probe</name><value>true</value></property>
<property><name>abaci.dag.previous.vertex.list.1</name><value>0</value></property>
<property><name>fs.trash.interval</name><value>10080</value></property>
<property><name>mapred.job.history.min.file.toCreateIndex.mb</name><value>500</value></property>
<property><name>mapred.skip.map.auto.incr.proc.count</name><value>true</value></property>
<property><name>abaci.use.dagagent</name><value>false</value></property>
<property><name>abaci.appmaster.disk.bytes.per.task</name><value>10240</value></property>
<property><name>abaci.appmaster.memory.bytes.per.task</name><value>26480</value></property>
<property><name>mapred.child.tmp</name><value>./tmp</value></property>
<property><name>mapred.tasktracker.taskmemorymanager.monitoring-interval</name><value>5000</value></property>
<property><name>slave.ugi.name</name><value>slave</value></property>
<property><name>mapred.map.output.buffer3</name><value>false</value></property>
<property><name>mapred.job.reduce.output.maxthrottle</name><value>0</value></property>
<property><name>dfs.datanode.http.address</name><value>0.0.0.0:8075</value></property>
<property><name>abaci.metamaster.statestore.session.timeout</name><value>600000</value></property>
<property><name>mapred.map.over.capacity.allowed</name><value>true</value></property>
<property><name>io.sort.spill.percent</name><value>0.80</value></property>
<property><name>mapred.job.shuffle.input.buffer.percent</name><value>0.70</value></property>
<property><name>dfs.max.objects</name><value>0</value></property>
<property><name>mapred.job.shuffle.service.enable</name><value>true</value></property>
<property><name>stream.map.streamprocessor</name><value>.%2Fpython2.7%2Fpython2.7.5%2Fbin%2Fpython+.%2Fnews_mid_map.py</value></property>
<property><name>abaci.shuffle.use.instance.notification</name><value>true</value></property>
<property><name>mapred.skip.map.max.skip.records</name><value>0</value></property>
<property><name>user.name</name><value>feed_vertical</value></property>
<property><name>mapred.normal.job.shuffle.service.reduce.awaited.percent</name><value>90</value></property>
<property><name>abaci.history.repo</name><value>rsync://yq01-tianqi-historyserver.dmop.baidu.com:18873/jobhistory</value></property>
<property><name>abaci.shuffleservice.start.cmd</name><value>sh -x ./abaci/hadoop-v2/hadoop/bin/start-shuffleservice.sh @heapsize@ @metahost@ @metaport@</value></property>
<property><name>abaci.job.suicide.min.app.master.execution.error.count</name><value>1440</value></property>
<property><name>fs.fms.impl</name><value>org.apache.hadoop.hdfs.FMSFileSystem</value></property>
<property><name>dce.shuffle.max.allow.map.capacity</name><value>1000000</value></property>
<property><name>hadoop.job.history.user.location</name><value>none</value></property>
<property><name>mapred.task.profile.maps</name><value>0-2</value></property>
<property><name>abaci.shuffleservice.http.acceptor.queuesize</name><value>400</value></property>
<property><name>dfs.replication.interval</name><value>3</value></property>
<property><name>mapred.local.dir</name><value>${hadoop.tmp.dir}/mapred/local</value></property>
<property><name>mapred.job.tracker.http.address</name><value>0.0.0.0:8030</value></property>
<property><name>mapred.compress.map.output</name><value>true</value></property>
<property><name>mapred.userlog.retain.hours</name><value>24</value></property>
<property><name>dce.shuffler.start.cmd</name><value>./hadoop-v2/dce/bin/start-shuffleworker.sh </value></property>
<property><name>abaci.job.tag.message.report.historyRuntime</name><value>例行作业Running: 运行时间过长, 持续@lastsTime@分钟</value></property>
<property><name>abaci.appmaster.rpc.handler</name><value>50</value></property>
<property><name>mapred.used.genericoptionsparser</name><value>true</value></property>
<property><name>mapred.create.symlink</name><value>yes</value></property>
<property><name>mapred.tasktracker.reduce.tasks.maximum</name><value>7</value></property>
<property><name>mapred.reducer.class</name><value>org.apache.hadoop.streaming.PipeReducer</value></property>
<property><name>mapred.job.max.existTime.check.enable</name><value>true</value></property>
<property><name>fs.hdfs2.impl</name><value>org.apache.hadoop.hdfs.NamespaceFileSystem</value></property>
<property><name>abaci.squeezer.auto.resize.memory.limit.enable</name><value>true</value></property>
<property><name>abaci.appmaster.http.address</name><value>0.0.0.0:8001</value></property>
<property><name>abaci.appmaster.start.cmd</name><value>./abaci/hadoop-v2/hadoop/bin/start-appmaster.sh @heapsize@ @metahost@ @metaport@ @rm@ @masterResourceGroup@ @slaveResourceGroup@ @jobid@ @queue@ @submittime@ @systemDir@ @recoverDir@ @abaciPath@ @isRecover@ @isLocal@</value></property>
<property><name>hadoop.job.ugi</name><value>feed_vertical,Tg28D3</value></property>
<property><name>dfs.data.dir</name><value>${hadoop.tmp.dir}/dfs/data</value></property>
<property><name>normandy.resource.manager.default.name</name><value>normandy://yq01-tianqi-normandy.dmop.baidu.com:9970</value></property>
<property><name>dfs.access.time.precision</name><value>3600000</value></property>
<property><name>dfs.replication.min</name><value>1</value></property>
<property><name>client.version</name><value>1.5.9</value></property>
<property><name>abaci.splittask.start.cmd</name><value>./abaci/hadoop-v2/hadoop/bin/start-splittask.sh @heapsize@ @jobid@ @masterhost@ @masterport@</value></property>
<property><name>abaci.shufflemaster.rpc.address</name><value>yq01-tianqi-historyserver.dmop.baidu.com:16001</value></property>
<property><name>fs.checkpoint.dir</name><value>${hadoop.tmp.dir}/dfs/namesecondary</value></property>
<property><name>fs.s3n.impl</name><value>org.apache.hadoop.fs.s3native.NativeS3FileSystem</value></property>
<property><name>abaci.job.tag.message.report.finishTimestamp</name><value>例行作业Running: ExpectFinishTime超时, 持续@lastsTime@分钟</value></property>
<property><name>abaci.shuffleservice.report.interval</name><value>60000</value></property>
<property><name>mapred.jobtracker.restart.recover</name><value>false</value></property>
<property><name>dce.multiple.reducers.per.shuffler</name><value>true</value></property>
<property><name>resource.manager.impl.normandy</name><value>com.baidu.inf.abaci.resource.NormandyResourceManager</value></property>
<property><name>dfs.client.authserver.force_stop</name><value>true</value></property>
<property><name>hadoop.logfile.size</name><value>10000000</value></property>
<property><name>abaci.job.enable.shuffle.works.capacity</name><value>false</value></property>
<property><name>dfs.client.speed.recheck.interval</name><value>30000</value></property>
<property><name>abaci.job.tag.message.report.failed</name><value>例行作业失败</value></property>
<property><name>abaci.job.reduce.max.capacity</name><value>3000</value></property>
<property><name>mapred.job.maps.output.maxthrottle</name><value>0</value></property>
<property><name>mapred.job.history.rpc.address</name><value>yq01-tianqi-historyserver.dmop.baidu.com:18258</value></property>
<property><name>abaci.job.tag.message.report.historyProcessSpeed</name><value>例行作业Running: 处理速度异常, 持续@lastsTime@分钟</value></property>
<property><name>abaci.shuffleservice.max.shuffleworks</name><value>20</value></property>
<property><name>mapred.inmem.merge.threshold</name><value>1000</value></property>
<property><name>abaci.squeezer.trial.run.vertex.memory.threshold</name><value>5000</value></property>
<property><name>mapred.job.map.capacity</name><value>100</value></property>
<property><name>ipc.client.connection.maxidletime</name><value>10000</value></property>
<property><name>abaci.kill.non.local.map</name><value>false</value></property>
<property><name>fs.checkpoint.size</name><value>67108864</value></property>
<property><name>stream.reduce.streamprocessor</name><value>.%2Fpython2.7%2Fpython2.7.5%2Fbin%2Fpython+.%2Fnews_mid_reduce.py</value></property>
<property><name>dfs.blockreport.intervalMsec</name><value>21600000</value></property>
<property><name>fs.s3.sleepTimeSeconds</name><value>10</value></property>
<property><name>dfs.client.block.write.retries</name><value>3</value></property>
<property><name>dce.shuffle.enable</name><value>false</value></property>
<property><name>mapred.reduce.slowstart.completed.maps.low.thresh</name><value>0.6</value></property>
<property><name>abaci.shuffleservice.resource.nodes</name><value>normandy-tianqi-app_phyPlugin,normandy-tianqi-rank-guide_phyPlugin,normandy-tianqi-rank-high_phyPlugin,normandy-tianqi-rank-low_phyPlugin,normandy-tianqi-dt_phyPlugin,normandy-tianqi-udw-etl_phyPlugin,normandy-tianqi-doris_phyPlugin</value></property>
<property><name>mapred.reduce.tasks</name><value>100</value></property>
<property><name>mapred.queue.names</name><value>default</value></property>
<property><name>mapred.job.keep.files.hours</name><value>2</value></property>
<property><name>io.seqfile.lazydecompress</name><value>true</value></property>
<property><name>abaci.job.map.child.memory.mb</name><value>1800</value></property>
<property><name>dce.rig.cluster.name</name><value>tianqi</value></property>
<property><name>abaci.history.mysql.address.name</name><value>szwg-hadoop-history-master01.szwg01.baidu.com</value></property>
<property><name>mapred.hosts.exclude</name><value>conf/mapred.hosts.exclude</value></property>
<property><name>dce.job.id</name><value>job_20171018134348_288277</value></property>
<property><name>abaci.job.suicide.min.ark.cache.error.count</name><value>50000</value></property>
<property><name>mapred.reduce.copy.backoff</name><value>300</value></property>
<property><name>dfs.replication</name><value>3</value></property>
<property><name>resource.manager.default.name</name><value>normandy://yq01-tianqi-normandy.dmop.baidu.com:9970</value></property>
<property><name>ipc.client.tcpnodelay</name><value>false</value></property>
<property><name>mapred.reduce.slowstart.completed.maps.high.thresh</name><value>1.0</value></property>
<property><name>abaci.appslave.expire.interval</name><value>180000</value></property>
<property><name>normandy.network.lost.confirm.second</name><value>300</value></property>
<property><name>mapred.output.format.class</name><value>org.apache.hadoop.mapred.TextOutputFormat</value></property>
<property><name>mapred.reduce.over.capacity.allowed</name><value>false</value></property>
<property><name>mapred.acls.enabled</name><value>true</value></property>
<property><name>mapred.tasktracker.dns.nameserver</name><value>default</value></property>
<property><name>abaci.shufflemaster.http.address</name><value>yq01-tianqi-historyserver.dmop.baidu.com:8030</value></property>
<property><name>mapred.submit.replication</name><value>10</value></property>
<property><name>abaci.shuffleservice.memory.mb</name><value>2000</value></property>
<property><name>mapred.job.split.file</name><value>afs://tianqi.afs.baidu.com:9902/app/dc/deva/system/mapred/job_20171018134348_288277/job.split</value></property>
<property><name>mapred.tasktracker.tasks.maxmemory</name><value>-1</value></property>
<property><name>fs.hdfs1.impl</name><value>org.apache.legacy.DistributedFileSystem</value></property>
<property><name>mapred.tasktracker.group</name><value>default</value></property>
<property><name>io.compression.codecs</name><value>org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.LzopCodec,org.apache.hadoop.io.compress.LzoCodec,org.apache.hadoop.io.compress.LzmaCodec,org.apache.hadoop.io.compress.QuickLzCodec,org.apache.hadoop.io.compress.Lz4Codec,org.apache.hadoop.io.compress.FourMcCodec,org.apache.hadoop.io.compress.ZstdCodec,org.apache.hadoop.io.compress.ZstCodec,org.apache.hadoop.io.compress.FourMzCodec,org.apache.hadoop.io.compress.FourMzFastCodec,org.apache.hadoop.io.compress.FourMzMediumCodec,org.apache.hadoop.io.compress.FourMzHighCodec,org.apache.hadoop.io.compress.FourMzUltraCodec</value></property>
<property><name>io.file.buffer.size</name><value>131072</value></property>
<property><name>dce.worker.max.used.memory.bytes</name><value>3000000000</value></property>
<property><name>mapred.map.tasks.speculative.execution</name><value>true</value></property>
<property><name>abaci.shuffleservice.http.acceptor.threads</name><value>1</value></property>
<property><name>abaci.history.mysql.db.name</name><value>SZWG_STON</value></property>
<property><name>normandy.network.lost.confirm.second normandy.network.lost.confirm.count</name><value>10000000</value></property>
<property><name>abaci.dagagent.start.cmd</name><value>./abaci/hadoop-v2/hadoop/bin/start-dagagent.sh @heapsize@ @jobid@ @masterhost@ @masterport@ @ismap@ @vertexId@ @pbrpcaddr@</value></property>
<property><name>mapred.map.max.attempts</name><value>4</value></property>
<property><name>mapred.job.shuffle.merge.percent</name><value>0.66</value></property>
<property><name>fs.har.impl</name><value>org.apache.hadoop.fs.HarFileSystem</value></property>
<property><name>fs.s3.buffer.dir</name><value>${hadoop.tmp.dir}/s3</value></property>
<property><name>abaci.job.tag.mon.processspeed.waveThreshold</name><value>0.5</value></property>
<property><name>mapred.skip.reduce.auto.incr.proc.count</name><value>true</value></property>
<property><name>dfs.http.address</name><value>0.0.0.0:8070</value></property>
<property><name>abaci.job.tag.message.history.normal.processSpeed</name><value>正常: @real@M/s &gt; @expect@M/s</value></property>
<property><name>child.max.memory</name><value>1800</value></property>
<property><name>idle.resource.manager.default.name</name><value>ark://szwg-hadoop-idle01.szwg01:22345</value></property>
<property><name>abaci.appmaster.tasks.per.cpu</name><value>1000000</value></property>
<property><name>dfs.replication.considerLoad</name><value>false</value></property>
<property><name>dce.shufflemaster.start.options</name><value>--dce_zk_node_path=@dce_zk_node_path@ --dce_zk_address=@dce_zk_address@ --dce_rig_cluster_name=@dce_rig_cluster_name@</value></property>
<property><name>bailing.job.failed.delay</name><value>false</value></property>
<property><name>mapred.job.queue.name</name><value>default</value></property>
<property><name>abaci.metamaster.appstatus.check.interval</name><value>60000</value></property>
<property><name>abaci.appmaster.disk.min.gb</name><value>1</value></property>
<property><name>abaci.appmaster.status.update.interval</name><value>10000</value></property>
<property><name>abaci.is.dag.job</name><value>true</value></property>
<property><name>hadoop.job.history.handler.count</name><value>20</value></property>
<property><name>abaci.squeezer.trial.run.queue.min.memory.mb</name><value>100</value></property>
<property><name>abaci.metamaster.statestore.path</name><value>/abaci/yq01-tianqi/meta</value></property>
<property><name>dfs.permissions</name><value>true</value></property>
<property><name>mapred.job.tracker.persist.jobstatus.hours</name><value>0</value></property>
<property><name>abaci.job.tag.schema</name><value>alias_name:alias_name, job_type:job_type, routine:routine, product_line:product_line, module:module, owner:owner, owner_team:owner_team, platform:platform, src_time:src_time, expect_start_time:expect_start_time, expect_finish_time:expect_finish_time, alarm_phone:alarm_phone, alarm_mail:alarm_mail</value></property>
<property><name>fs.file.impl</name><value>org.apache.hadoop.fs.LocalFileSystem</value></property>
<property><name>dfs.block.size</name><value>268435456</value></property>
<property><name>dfs.https.address</name><value>0.0.0.0:8470</value></property>
<property><name>ipc.client.kill.max</name><value>10</value></property>
<property><name>mapred.tasktracker.map.tasks.maximum</name><value>7</value></property>
<property><name>abaci.appmaster.resource.node</name><value>abaci.appmaster</value></property>
<property><name>abaci.appslave.max.resuse</name><value>50</value></property>
<property><name>mapred.job.tracker.persist.jobstatus.dir</name><value>/system/jobsinfo</value></property>
<property><name>abaci.job.tag.message.recover</name><value>处理速度恢复正常，持续@lastsTime@分钟</value></property>
<property><name>dce.worker.port</name><value>8888</value></property>
<property><name>dfs.default.chunk.view.size</name><value>32768</value></property>
<property><name>abaci.app.launch.queue.size</name><value>30</value></property>
<property><name>dce.rig.udt.host</name><value>http://10.216.216.67:9999/data/dstream_rig/rig_dce</value></property>
<property><name>mapred.reduce.slowstart.completed.maps</name><value>0.01</value></property>
<property><name>abaci.appmaster.failover.timeout</name><value>60000</value></property>
<property><name>mapred.mapper.class</name><value>org.apache.hadoop.streaming.PipeMapper</value></property>
<property><name>abaci.job.tag.message.report.killed</name><value>例行作业Killed</value></property>
<property><name>io.sort.mb</name><value>128</value></property>
<property><name>ipc.server.listen.queue.size</name><value>10240</value></property>
<property><name>abaci.job.tag.message.start.timestamp</name><value>ExpectStartTime超时, @real@ &gt; @expect@</value></property>
<property><name>dfs.libdfs.buffer.size</name><value>1048576</value></property>
<property><name>dce.shuffle.enable.for.java.job</name><value>false</value></property>
<property><name>dce.shuffler.resource.nodes</name><value>normandy-tianqi-app_phyPlugin,normandy-tianqi-rank-guide_phyPlugin,normandy-tianqi-rank-high_phyPlugin,normandy-tianqi-udw-etl_phyPlugin,normandy-tianqi-doris_phyPlugin</value></property>
<property><name>fs.hsftp.impl</name><value>org.apache.hadoop.hdfs.HsftpFileSystem</value></property>
<property><name>abaci.shuffleservice.http.status.inquiry.port</name><value>48765</value></property>
<property><name>mapred.cache.files.timestamps</name><value>1509041590000</value></property>
<property><name>mapred.job.map.output.maxthrottle</name><value>0</value></property>
<property><name>abaci.squeezer.trial.run.vertex.cpu.threshold</name><value>20</value></property>
<property><name>slave.ugi.group</name><value>slave</value></property>
<property><name>dce.rig.post.delta.time</name><value>60</value></property>
<property><name>dfs.datanode.dns.nameserver</name><value>default</value></property>
<property><name>mapred.child.java.opts</name><value>@heapsize@ -XX:MaxDirectMemorySize=@directmemory@m -XX:ErrorFile=@logdir@/@taskid@/hs_err_pid%p.log -XX:+UseParallelGC -XX:ParallelGCThreads=4 -XX:GCTimeRatio=10 -XX:YoungGenerationSizeIncrement=20 -XX:TenuredGenerationSizeIncrement=20 -XX:AdaptiveSizeDecrementScaleFactor=2 -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=@logdir@/@taskid@/child_heapDump.core -Xloggc:@logdir@/@taskid@/gclog</value></property>
<property><name>dfs.replication.max</name><value>15</value></property>
<property><name>mapred.jobtracker.groupcapacityscheduler.assignmultiple</name><value>true</value></property>
<property><name>map.sort.class</name><value>org.apache.hadoop.util.QuickSort</value></property>
<property><name>mapred.job.shuffle.service.enable.min.maps</name><value>4000</value></property>
<property><name>hadoop.job.history.location</name><value>file:///home/mapred/history</value></property>
<property><name>mapred.jobtracker.instrumentation</name><value>org.apache.hadoop.mapred.JobTrackerMetricsInst</value></property>
<property><name>dfs.hosts.exclude</name><value>conf/dfs.hosts.exclude</value></property>
<property><name>map.output.shuffle.batchnum</name><value>10</value></property>
<property><name>mapred.job.reduce.output.minthrottle</name><value>0</value></property>
<property><name>topology.node.switch.mapping.impl</name><value>org.apache.hadoop.net.ScriptBasedMapping</value></property>
<property><name>dfs.datanode.dns.interface</name><value>default</value></property>
<property><name>abaci.shuffleservice.http.data.provider.port</name><value>49860</value></property>
<property><name>mapred.output.compression.type</name><value>BLOCK</value></property>
<property><name>mapred.skip.attempts.to.start.skipping</name><value>2</value></property>
<property><name>fs.raid.impl</name><value>org.apache.hadoop.hdfs.DistributedFileSystem</value></property>
<property><name>mapred.task.maxmemory</name><value>-1</value></property>
<property><name>io.map.index.skip</name><value>0</value></property>
<property><name>abaci.appmaster.statestore.path</name><value>/abaci/yq01-tianqi/jobs</value></property>
<property><name>zookeeper.server.list</name><value>yq01-tianqi-zk.dmop.baidu.com:2181</value></property>
<property><name>fs.s3.maxRetries</name><value>4</value></property>
<property><name>dfs.namenode.logging.level</name><value>info</value></property>
<property><name>mapred.free.interval</name><value>300000</value></property>
<property><name>mapred.userlog.limit.kb</name><value>10240</value></property>
<property><name>mapred.map.over.capacity.blacklist</name><value>distcp|DCS-Get-.*</value></property>
<property><name>mapred.input.format.class</name><value>org.apache.hadoop.mapred.TextInputFormat</value></property>
<property><name>fs.afs.impl</name><value>org.apache.hadoop.fs.DFileSystem</value></property>
<property><name>abaci.dag.next.vertex.list0</name><value>1</value></property>
<property><name>abaci.dce.shuffle.alarm.mail</name><value>liuhe01@baidu.com,sunyaoguang@baidu.com,mabinbin@baidu.com,songzhan@baidu.com,songxianzheng@baidu.com,liyin@baidu.com,zhangjianwei@baidu.com,yinchengchen@baidu.com</value></property>
<property><name>hadoop.rpc.socket.factory.class.default</name><value>org.apache.hadoop.net.StandardSocketFactory</value></property>
<property><name>resource.manager.http.address</name><value>yq01-tianqi-normandy.dmop.baidu.com:8033</value></property>
<property><name>abaci.shuffleservice.gc.gap</name><value>25</value></property>
<property><name>pbrpc.client.rw.timeout</name><value>15000</value></property>
<property><name>fs.hftp.impl</name><value>org.apache.hadoop.hdfs.HftpFileSystem</value></property>
<property><name>mapred.job.submit.dir</name><value>afs://tianqi.afs.baidu.com:9902/app/dc/deva/system/mapred/job_20171018134348_288277</value></property>
<property><name>dfs.namenode.handler.count</name><value>100</value></property>
<property><name>fs.kfs.impl</name><value>org.apache.hadoop.fs.kfs.KosmosFileSystem</value></property>
<property><name>dfs.rootdir.replication</name><value>3</value></property>
<property><name>dce.zk.node.path</name><value>/dce_tianqi_shufflers</value></property>
<property><name>mapred.map.tasks</name><value>3519</value></property>
<property><name>user.info.file</name><value>conf/hadoop-user-info.properties</value></property>
<property><name>mapred.local.dir.minspacekill</name><value>0</value></property>
<property><name>fs.hdfs.impl</name><value>org.apache.hadoop.hdfs.DistributedFileSystem</value></property>
<property><name>mapred.jobtracker.completeuserjobs.maximum</name><value>15</value></property>
<property><name>abaci.dagappmaster.start.cmd</name><value>./abaci/hadoop-v2/hadoop/bin/start-dagappmaster.sh @heapsize@ @metahost@ @metaport@ @rm@ @masterResourceGroup@ @slaveResourceGroup@ @jobid@ @queue@ @submittime@ @systemDir@ @recoverDir@ @abaciPath@ @isRecover@ @isLocal@</value></property>
<property><name>dfs.client.slow.write.limit</name><value>1000000</value></property>
<property><name>dce.shuffle.max.allow.reduces</name><value>1000000</value></property>
<property><name>mapred.job.reduces.output.minthrottle</name><value>0</value></property>
<property><name>abaci.job.reduce.child.memory.mb</name><value>1800</value></property>
<property><name>dce.shuffle.session.output.dir</name><value>/app/dc/deva/system/sessions</value></property>
<property><name>abaci.shuffleservice.rpc.port</name><value>49880</value></property>
<property><name>abaci.shuffleservice.http.busythreads</name><value>3</value></property>
<property><name>dce.shuffle.comparator.enable</name><value>true</value></property>
<property><name>dce.shuffle.enable.for.cpp.job</name><value>true</value></property>
<property><name>abaci.shuffle.service.ram.manager.buffer.size.mb</name><value>256</value></property>
<property><name>abaci.appmaster.recover.running.task</name><value>true</value></property>
<property><name>dfs.blockreport.initialDelay</name><value>0</value></property>
<property><name>normandy.network.lost.confirm.count</name><value>30</value></property>
<property><name>mapred.min.split.size</name><value>0</value></property>
<property><name>fs.ftp.impl</name><value>org.apache.hadoop.fs.ftp.FTPFileSystem</value></property>
<property><name>dfs.secondary.http.address</name><value>0.0.0.0:8090</value></property>
<property><name>mapred.output.compression.codec</name><value>org.apache.hadoop.io.compress.GzipCodec</value></property>
<property><name>dfs.batch.open.file.max</name><value>4096</value></property>
<property><name>mapred.cache.files</name><value>afs://tianqi.afs.baidu.com:9902/app/dc/deva/system/mapred/job_20171018134348_288277/job.xml#job.xml</value></property>
<property><name>dce.shuffle.sessionspec.sortermaxbytes</name><value>314572800</value></property>
<property><name>abaci.job.map.max.capacity</name><value>10000</value></property>
<property><name>dfs.web.ugi</name><value>webuser,webgroup</value></property>
<property><name>mapred.task.profile</name><value>false</value></property>
<property><name>hce.joindelay.milli</name><value>5000</value></property>
<property><name>mapred.reduce.parallel.copies</name><value>80</value></property>
<property><name>abaci.appmaster.cleanup.waiting.time</name><value>30000</value></property>
<property><name>dfs.heartbeat.interval</name><value>3</value></property>
<property><name>hadoop.job.history.cleandays</name><value>2</value></property>
<property><name>local.cache.size</name><value>30737418240</value></property>
<property><name>io.sort.factor</name><value>80</value></property>
<property><name>mapred.shuffle.service.http.address</name><value>0.0.0.0:8060</value></property>
<property><name>mapred.input.dir</name><value>hdfs://nj01-nanling-hdfs.dmop.baidu.com:54310/app/mco_userprofile/user/xingwanjia/wise/sbfeed/*/20171027/feed-al4-online-pipe/feed-al4-online-pipe_2017102701*[0-9],hdfs://nj01-nanling-hdfs.dmop.baidu.com:54310/app/mco_userprofile/user/zhucan/wise/sbfeed/rdc/*/20171027/feed-al4-online-pipe/data/feed-al4-online-pipe_2017102701*[0-9],hdfs://nj01-nanling-hdfs.dmop.baidu.com:54310/app/mco_userprofile/user/zhucan/wise/sbfeed/rdc/*/20171027/mbnews-pipe/data/mbnews-pipe_2017102701*[0-9]</value></property>
<property><name>abaci.metamaster.rpc.address</name><value>yq01-tianqi-job.dmop.baidu.com:54311</value></property>
<property><name>mapred.task.timeout</name><value>0</value></property>
<property><name>abaci.job.tag.mon.runningScale</name><value>0.5</value></property>
<property><name>dfs.safemode.extension</name><value>30000</value></property>
<property><name>abaci.normandy.instancemanager.free.instance.timeout</name><value>72000</value></property>
<property><name>merge.parallel.threads</name><value>2</value></property>
<property><name>abaci.appmaster.kill.reduce</name><value>0</value></property>
<property><name>abaci.archive.path</name><value>afs://tianqi.afs.baidu.com:9902/app/dc/deva/system/share/abaci-3.30.4_20170925_casio_new_dce.tar.gz#abaci</value></property>
<property><name>dfs.new.slow.read</name><value>false</value></property>
<property><name>abaci.job.tag.mon.sms.servers</name><value>emp01.baidu.com:15009, emp02.baidu.com:15009</value></property>
<property><name>ipc.client.idlethreshold</name><value>30000</value></property>
<property><name>ipc.server.tcpnodelay</name><value>false</value></property>
<property><name>hadoop.logfile.count</name><value>10</value></property>
<property><name>mapred.output.dir</name><value>afs://tianqi.afs.baidu.com:9902/user/feed/vertical/user/xingyongyue/feed/igc_ctr_report_xingyongyue/20171027/ctr_2017102701</value></property>
<property><name>https.keystore.info.rsrc</name><value>sslinfo.xml</value></property>
<property><name>hadoop.log.level</name><value>4</value></property>
<property><name>fs.s3.block.size</name><value>67108864</value></property>
<property><name>mapred.map.output.compression.codec</name><value>org.apache.hadoop.io.compress.LzoCodec</value></property>
<property><name>mapred.task.cache.levels</name><value>2</value></property>
<property><name>mapred.queue.default.acl-submit-job</name><value>*</value></property>
<property><name>abaci.normandy.monitor.interval</name><value>10000</value></property>
<property><name>stream.numinputspecs</name><value>1</value></property>
<property><name>mapred.tasktracker.dns.interface</name><value>default</value></property>
<property><name>dfs.client.slow.read.limit</name><value>1000000</value></property>
<property><name>pbrpc.client.connect.timeout</name><value>10000</value></property>
<property><name>fs.http.impl</name><value>org.apache.hadoop.hdfs.HttpReadOnlyFileSystem</value></property>
<property><name>abaci.job.tag.message.finish.timestamp</name><value>ExpectFinishTime超时, @real@ &gt; @expect@</value></property>
<property><name>mapred.job.shuffle.service.enable.min.reduces</name><value>1000</value></property>
<property><name>mapred.output.key.class</name><value>org.apache.hadoop.io.Text</value></property>
<property><name>dfs.client.add.datanode</name><value>true</value></property>
<property><name>dfs.tracking.read.speed.enable</name><value>true</value></property>
<property><name>mapred.job.shuffle.service.enable.job.priority.threshold</name><value>HIGH</value></property>
<property><name>fms.pool.map.file</name><value>conf/fms-pool-info.properties</value></property>
<property><name>mapred.max.tracker.failures</name><value>4</value></property>
<property><name>abaci.job.tag.mon.recoverScale</name><value>0.1</value></property>
<property><name>dfs.df.interval</name><value>300000</value></property>
<property><name>abaci.squeezer.resource.probe.log.enable</name><value>false</value></property>
<property><name>mapred.cache.archives</name><value>afs://tianqi.afs.baidu.com:9902/user/feed/vertical/tools/python2.7.5.tar.gz#python2.7,afs://tianqi.afs.baidu.com:9902/app/dc/deva/system/share/abaci-3.30.4_20170925_casio_new_dce.tar.gz#abaci,afs://tianqi.afs.baidu.com:9902/app/dc/deva/system/mapred/job_20171018134348_288277/job.jar#.</value></property>
<property><name>dce.rig.enabled</name><value>false</value></property>
<property><name>abaci.appmaster.wait.metamaster.time</name><value>600000</value></property>
<property><name>abaci.shuffleservice.http.threads</name><value>803</value></property>
<property><name>abaci.squeezer.enable</name><value>false</value></property>
<property><name>abaci.shuffleservice.priority</name><value>10</value></property>
<property><name>abaci.normandy.na.port</name><value>48901</value></property>
<property><name>jobclient.output.filter</name><value>FAILED</value></property>
<property><name>abaci.appmaster.memory.min.mb</name><value>350</value></property>
<property><name>mapred.tasktracker.procfsbasedprocesstree.sleeptime-before-sigkill</name><value>5000</value></property>
<property><name>mapred.tasktracker.free.reserved</name><value>104857600</value></property>
<property><name>io.serializations</name><value>org.apache.hadoop.io.serializer.WritableSerialization</value></property>
<property><name>mapred.task.hce.accept.limit</name><value>120000</value></property>
<property><name>dfs.support.batch.list</name><value>true</value></property>
<property><name>io.seqfile.compress.blocksize</name><value>1000000</value></property>
<property><name>mapred.jobtracker.taskScheduler</name><value>org.apache.hadoop.mapred.GroupCapacityFIFOScheduler</value></property>
<property><name>job.end.retry.attempts</name><value>0</value></property>
<property><name>ipc.client.connect.max.retries</name><value>30</value></property>
<property><name>abaci.is.queuename.prefix</name><value>false</value></property>
<property><name>mapred.job.max.existTime.check.interval.millisecond</name><value>604800000</value></property>
<property><name>client.ip</name><value>10.100.50.154</value></property>
<property><name>mapred.map.runner.class</name><value>org.apache.hadoop.streaming.PipeMapRunner</value></property>
<property><name>webinterface.private.actions</name><value>false</value></property>
<property><name>abaci.shuffle.service.parallel.inmemory.merger.num</name><value>1</value></property>
<property><name>mapred.tasktracker.indexcache.mb</name><value>100</value></property>
<property><name>fs.checkpoint.edits.dir</name><value>${fs.checkpoint.dir}</value></property>
<property><name>abaci.job.reduce.cpu.percent</name><value>80</value></property>
<property><name>mapred.output.value.class</name><value>org.apache.hadoop.io.Text</value></property>
<property><name>tasktracker.http.threads</name><value>200</value></property>
<property><name>abaci.tasklog.http.port</name><value>8900</value></property>
<property><name>mapred.job.tracker.handler.count</name><value>100</value></property>
<property><name>resource.phy.nodes</name><value>tianqi-app_phy,tianqi-rank-guide_phy,tianqi-rank-high_phy,tianqi-appmaster_phy,tianqi-rank-low_phy,tianqi-dt_phy,tianqi-udw-etl_phy,tianqi-doris_phy,tianqi-bigpipe-ui_phy</value></property>
<property><name>keep.failed.task.files</name><value>false</value></property>
<property><name>mapred.output.compress</name><value>false</value></property>
<property><name>abaci.squeezer.trial.run.exclude.reduce.vertex</name><value>false</value></property>
<property><name>mapred.jobtracker.job.history.block.size</name><value>3145728</value></property>
<property><name>mapred.skip.reduce.max.skip.groups</name><value>0</value></property>
<property><name>abaci.shuffleservice.disk.gb</name><value>1024</value></property>
<property><name>abaci.history.mysql.address.port</name><value>3306</value></property>
<property><name>dfs.datanode.address</name><value>0.0.0.0:50010</value></property>
<property><name>dfs.datanode.max.xcievers</name><value>1024</value></property>
<property><name>dfs.datanode.https.address</name><value>0.0.0.0:8475</value></property>
<property><name>fs.s3.impl</name><value>org.apache.hadoop.fs.s3.S3FileSystem</value></property>
<property><name>abaci.job.alarm.admin.phone</name><value>18612540350</value></property>
<property><name>abaci.resident.appmaster.start.cmd</name><value>./abaci/hadoop-v2/hadoop/bin/start-appmaster.sh @heapsize@ @metahost@ @metaport@</value></property>
<property><name>mapred.jar</name><value>afs://tianqi.afs.baidu.com:9902/app/dc/deva/system/mapred/job_20171018134348_288277/job.jar</value></property>
<property><name>mapred.jobclient.check.url</name><value>true</value></property>
<property><name>hadoop.tmp.dir</name><value>/home/${user.name}/hadoop-v2/hadoop-data</value></property>
<property><name>mapred.line.input.format.linespermap</name><value>1</value></property>
<property><name>dfs.datanode.du.reserved</name><value>21474836480</value></property>
<property><name>topology.script.number.args</name><value>100</value></property>
<property><name>abaci.converted.queue.name</name><value>feed-buffer</value></property>
<property><name>mapred.job.priority</name><value>VERY_HIGH</value></property>
<property><name>fs.default.name</name><value>afs://tianqi.afs.baidu.com:9902</value></property>
<property><name>abaci.job.alarm.admin.mail</name><value>jiangtao02</value></property>
<property><name>dfs.balance.bandwidthPerSec</name><value>31457280</value></property>
<property><name>mapred.job.perf.enable</name><value>true</value></property>
<property><name>abaci.job.map.cpu.percent</name><value>80</value></property>
<property><name>mapred.local.dir.minspacestart</name><value>0</value></property>
<property><name>mapred.jobtracker.maxtasks.per.job</name><value>-1</value></property>
<property><name>dce.shuffle.writer.max.mb</name><value>388</value></property>
<property><name>mapred.job.reduces.output.maxthrottle</name><value>0</value></property>
<property><name>abaci.shuffle.service.parallel.event.fetchers</name><value>2</value></property>
<property><name>abaci.job.tag.message.history.runtime</name><value>运行时间过长, @real@分钟 &gt; @expect@分钟</value></property>
<property><name>mapred.overall.shuffle.service.enable</name><value>true</value></property>
<property><name>mapred.reduce.max.attempts</name><value>4</value></property>
<property><name>mapred.job.auditsFile.max.existTime.millisecond</name><value>15552000000</value></property>
<property><name>mapred.job.garbagefile.clean.maximum.interval</name><value>15552000000</value></property>
<property><name>mapred.job.tracker</name><value>yq01-tianqi-job.dmop.baidu.com:54311</value></property>
<property><name>dfs.namenode.decommission.interval</name><value>300</value></property>
<property><name>mapred.job.setup.cleanup.needed</name><value>false</value></property>
<property><name>dfs.name.edits.dir</name><value>${dfs.name.dir}</value></property>
<property><name>mapred.job.groups</name><value>default</value></property>
<property><name>abaci.support.middle.data.on.dfs</name><value>false</value></property>
<property><name>mapred.job.map.output.minthrottle</name><value>0</value></property>
<property><name>mapred.tasktracker.instrumentation</name><value>org.apache.hadoop.mapred.TaskTrackerMetricsInst</value></property>
<property><name>mapred.job.groups.check</name><value>false</value></property>
<property><name>mapred.recover.dir</name><value>/app/dc/deva/system/recover</value></property>
<property><name>mapred.tasktracker.expiry.interval</name><value>180000</value></property>
<property><name>io.sort.record.percent</name><value>0.16</value></property>
<property><name>dfs.safemode.threshold.pct</name><value>1.500f</value></property>
<property><name>abaci.dagagent.replace</name><value>false</value></property>
<property><name>mapred.job.tracker.persist.jobstatus.active</name><value>true</value></property>
<property><name>mapred.job.reduce.capacity</name><value>100</value></property>
<property><name>dfs.name.dir</name><value>${hadoop.tmp.dir}/dfs/name</value></property>
<property><name>abaci.appslave.start.cmd</name><value>./abaci/hadoop-v2/hadoop/bin/start-appslave.sh @heapsize@ @jobid@ @masterhost@ @masterport@ @ismap@ @vertexId@ @pbrpcaddr@</value></property>
<property><name>fs.checkpoint.period</name><value>3600</value></property>
<property><name>abaci.shuffleservice.cpu.percent</name><value>60</value></property>
<property><name>dce.shuffle.max.allow.maps</name><value>1000000</value></property>
<property><name>io.skip.checksum.errors</name><value>false</value></property>
<property><name>abaci.job.default.configured.highversion.baseenv</name><value>centos6u3_hadoop</value></property>
<property><name>dfs.datanode.handler.count</name><value>50</value></property>
<property><name>mapred.jobclient.check.counters</name><value>false</value></property>
<property><name>abaci.shuffle.service.index.cache.size.mb</name><value>200</value></property>
<property><name>dfs.delete.trash</name><value>1</value></property>
<property><name>mapred.temp.dir</name><value>${hadoop.tmp.dir}/mapred/temp</value></property>
<property><name>dce.shuffle.max.shard.per.shuffler</name><value>1000000</value></property>
<property><name>hadoop.native.lib</name><value>true</value></property>
<property><name>abaci.squeezer.debug</name><value>true</value></property>
<property><name>fs.webhdfs.impl</name><value>org.apache.hadoop.fs.community.http.HttpFSFileSystem</value></property>
<property><name>dfs.datanode.ipc.address</name><value>0.0.0.0:50020</value></property>
<property><name>mapred.working.dir</name><value>afs://tianqi.afs.baidu.com:9902/user/feed_vertical</value></property>
<property><name>mapred.job.reduce.input.buffer.percent</name><value>0.0</value></property>
<property><name>mapred.job.maps.output.minthrottle</name><value>0</value></property>
</configuration>